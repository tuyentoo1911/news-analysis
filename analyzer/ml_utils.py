import re
import string
import numpy as np
from pathlib import Path
import os
import math
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification


def preprocess_text(text):
    """
    Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
    """
    if not text or not isinstance(text, str):
        return ""

    # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng
    text = text.lower()

    # Lo·∫°i b·ªè d·∫•u c√¢u
    text = text.translate(str.maketrans('', '', string.punctuation))

    # Lo·∫°i b·ªè s·ªë
    text = re.sub(r'\d+', '', text)

    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
    text = ' '.join(text.split())

    return text


def predict_fake_news(text):
    """
    THU·∫¨T TO√ÅN PH√ÇN T√çCH TIN GI·∫¢ ƒê∆Ø·ª¢C C·∫¢I TI·∫æN
    - Gi·∫£m bias, confidence th·ª±c t·∫ø h∆°n
    - Th√™m nhi·ªÅu y·∫øu t·ªë ph√¢n t√≠ch
    - Logic c√¢n b·∫±ng h∆°n
    """
    try:
        # Ki·ªÉm tra ƒë·∫ßu v√†o
        if not text or not isinstance(text, str):
            return {
                'is_fake': False,
                'confidence': 0.5,
                'message': 'Kh√¥ng th·ªÉ ph√¢n t√≠ch vƒÉn b·∫£n tr·ªëng',
                'processed_text': '',
                'analysis_details': {}
            }

        processed_text = preprocess_text(text)

        if not processed_text or len(processed_text.strip()) < 10:
            return {
                'is_fake': False,
                'confidence': 0.6,
                'message': 'VƒÉn b·∫£n qu√° ng·∫Øn ƒë·ªÉ ph√¢n t√≠ch ch√≠nh x√°c',
                'processed_text': processed_text,
                'analysis_details': {'reason': 'text_too_short'}
            }

        # =================================
        # C√ÅC CH·ªà S·ªê PH√ÇN T√çCH ƒê∆Ø·ª¢C C·∫¢I TI·∫æN
        # =================================

        analysis_details = {}

        # 1. PH√ÇN T√çCH T·ª™ KH√ìA ƒê√ÅNG NG·ªú (Gi·∫£m tr·ªçng s·ªë)
        suspicious_words = [
            # Clickbait words
            'gi·∫≠t g√¢n', 's·ªëc', 'kh√¥ng th·ªÉ tin ƒë∆∞·ª£c', 'b√≠ m·∫≠t', 'kh·ªßng khi·∫øp',
            'n√≥ng h·ªïi', 'bom t·∫•n', 'ƒë·ªôc quy·ªÅn', 'l·∫° l√πng', 'kinh ho√†ng',
            'b·∫•t ng·ªù', 'ch·∫•n ƒë·ªông', 'r√∫ng ƒë·ªông', 'g√¢y s·ªët', 'viral',
            # Th√™m t·ª´ ti·∫øng Vi·ªát
            'kinh d·ªã', 'r·ª£n ng∆∞·ªùi', 'cho√°ng v√°ng', 'th√≥t tim', 'ƒë·ªânh cao',
            'tuy·ªát ƒë·ªëi', 'nh·∫•t ƒë·ªãnh', '100%', 'ch·∫Øc ch·∫Øn', 'kh√¥ng ai bi·∫øt'
        ]

        suspicious_found = [word for word in suspicious_words if word in processed_text]
        suspicious_score = len(suspicious_found) * 0.08  # GI·∫¢M t·ª´ 0.15 xu·ªëng 0.08
        analysis_details['suspicious_words'] = suspicious_found

        # 2. PH√ÇN T√çCH CH·ªà B√ÅO TIN C·∫¨Y (TƒÉng tr·ªçng s·ªë)
        reliable_indicators = [
            # Ngu·ªìn tin ch√≠nh th·ª©c
            'theo b√°o', 'ngu·ªìn tin', 'ch√≠nh th·ª©c', 'th√¥ng c√°o', 'b√°o c√°o',
            'nghi√™n c·ª©u', 'chuy√™n gia', 'ph√°t ng√¥n vi√™n', 'c∆° quan ch·ª©c nƒÉng',
            # Th√™m ngu·ªìn c·ª• th·ªÉ
            'vnexpress', 'tu·ªïi tr·∫ª', 'thanh ni√™n', 'vietnamnet', 'dantri',
            'b·ªô y t·∫ø', 'b·ªô gi√°o d·ª•c', 'th·ªß t∆∞·ªõng', 'ch√≠nh ph·ªß',
            'ƒë·∫°i h·ªçc', 'ti·∫øn sƒ©', 'gi√°o s∆∞', 'b√°c sƒ©', 'lu·∫≠t s∆∞'
        ]

        reliable_found = [word for word in reliable_indicators if word in processed_text]
        reliable_score = len(reliable_found) * 0.12  # TƒÇNG t·ª´ 0.1 l√™n 0.12
        analysis_details['reliable_indicators'] = reliable_found

        # 3. PH√ÇN T√çCH C·∫§U TR√öC VƒÇN B·∫¢N
        structure_score = 0

        # ƒê·ªô d√†i vƒÉn b·∫£n
        text_length = len(processed_text)
        if text_length < 50:
            structure_score += 0.15  # Qu√° ng·∫Øn
        elif text_length < 100:
            structure_score += 0.08  # H∆°i ng·∫Øn
        elif text_length > 2000:
            structure_score -= 0.05  # D√†i = t·ªët

        # T·ª∑ l·ªá d·∫•u ch·∫•m than
        exclamation_count = text.count('!')
        exclamation_ratio = exclamation_count / len(text) if text else 0
        if exclamation_ratio > 0.02:  # >2% l√† qu√° nhi·ªÅu
            structure_score += min(exclamation_ratio * 5, 0.2)

        # T·ª∑ l·ªá ch·ªØ in hoa
        upper_ratio = sum(1 for c in text if c.isupper()) / len(text) if text else 0
        if upper_ratio > 0.05:  # >5% l√† qu√° nhi·ªÅu
            structure_score += min(upper_ratio * 2, 0.15)

        analysis_details['structure'] = {
            'length': text_length,
            'exclamation_ratio': round(exclamation_ratio, 4),
            'upper_ratio': round(upper_ratio, 4)
        }

        # 4. PH√ÇN T√çCH NG√îN NG·ªÆ T√åNH C·∫¢M
        emotional_words = [
            'y√™u', 'gh√©t', 't·ª©c gi·∫≠n', 'ph·∫´n n·ªô', 'cƒÉm th√π', 'khi·∫øp s·ª£',
            'lo l·∫Øng', 'ho·∫£ng s·ª£', 'ph·∫•n kh√≠ch', 'h√†o h·ª©ng'
        ]
        emotional_score = len([w for w in emotional_words if w in processed_text]) * 0.05

        # 5. KI·ªÇM TRA S·ªê LI·ªÜU V√Ä TH√îNG TIN C·ª§ TH·ªÇ
        has_numbers = bool(re.search(r'\d', text))
        has_dates = bool(re.search(r'\d{1,2}[/-]\d{1,2}[/-]\d{2,4}', text))
        has_specific_info = any(indicator in text.lower() for indicator in [
            'nghi√™n c·ª©u cho th·∫•y', 'theo th·ªëng k√™', 'd·ªØ li·ªáu', 'ph·∫ßn trƒÉm', '%'
        ])

        specificity_score = 0
        if has_numbers:
            specificity_score -= 0.05
        if has_dates:
            specificity_score -= 0.08
        if has_specific_info:
            specificity_score -= 0.1

        analysis_details['specificity'] = {
            'has_numbers': has_numbers,
            'has_dates': has_dates,
            'has_specific_info': has_specific_info
        }

        # =================================
        # T√çNH ƒêI·ªÇM T·ªîNG H·ª¢P (C·∫¢I TI·∫æN)
        # =================================

        # Base score b·∫Øt ƒë·∫ßu t·ª´ 0.4 thay v√¨ 0
        base_score = 0.4

        # T·ªïng h·ª£p c√°c ƒëi·ªÉm
        total_fake_score = (
            base_score +
            suspicious_score +
            structure_score +
            emotional_score +
            specificity_score -
            reliable_score
        )

        # Th√™m y·∫øu t·ªë ng·∫´u nhi√™n NH·ªé H∆†N
        import random
        random_factor = random.uniform(-0.05, 0.05)  # GI·∫¢M t·ª´ ¬±0.1 xu·ªëng ¬±0.05
        total_fake_score += random_factor

        # Chu·∫©n h√≥a ƒëi·ªÉm s·ªë v·ªõi h√†m sigmoid ƒë·ªÉ tr√°nh c·ª±c tr·ªã
        normalized_score = 1 / (1 + math.exp(-(total_fake_score - 0.5) * 6))

        # =================================
        # QUY·∫æT ƒê·ªäNH K·∫æT QU·∫¢
        # =================================

        is_fake = normalized_score > 0.55  # TƒÉng ng∆∞·ª°ng l√™n 0.55

        # T√çNH CONFIDENCE TH·ª∞C T·∫æ H∆†N
        if is_fake:
            # Confidence cho tin gi·∫£
            raw_confidence = normalized_score
            if raw_confidence > 0.9:
                confidence = 0.75 + (raw_confidence - 0.9) * 1.5  # Max ~0.9
            elif raw_confidence > 0.7:
                confidence = 0.65 + (raw_confidence - 0.7) * 0.5  # 0.65-0.75
            else:
                confidence = 0.55 + (raw_confidence - 0.55) * 0.67  # 0.55-0.65
        else:
            # Confidence cho tin th·∫≠t
            raw_confidence = 1 - normalized_score
            if raw_confidence > 0.8:
                confidence = 0.7 + (raw_confidence - 0.8) * 1.0   # Max ~0.9
            elif raw_confidence > 0.6:
                confidence = 0.6 + (raw_confidence - 0.6) * 0.5   # 0.6-0.7
            else:
                confidence = 0.5 + raw_confidence * 0.2            # 0.5-0.6

        # Cap confidence t·ªëi ƒëa 0.89
        confidence = min(confidence, 0.89)

        # ƒê·∫∑c bi·ªát: N·∫øu kh√¥ng c√≥ ƒë·ªß th√¥ng tin, gi·∫£m confidence
        if len(processed_text) < 100 and not reliable_found and not suspicious_found:
            confidence = max(confidence * 0.7, 0.5)  # Gi·∫£m xu·ªëng, t·ªëi thi·ªÉu 0.5

        analysis_details['scoring'] = {
            'suspicious_score': round(suspicious_score, 3),
            'reliable_score': round(reliable_score, 3),
            'structure_score': round(structure_score, 3),
            'emotional_score': round(emotional_score, 3),
            'specificity_score': round(specificity_score, 3),
            'total_fake_score': round(total_fake_score, 3),
            'normalized_score': round(normalized_score, 3),
            'random_factor': round(random_factor, 3)
        }

        # Th√¥ng ƒëi·ªáp d·ª±a tr√™n k·∫øt qu·∫£
        if confidence < 0.6:
            message = "ƒê·ªô tin c·∫≠y ph√¢n t√≠ch th·∫•p - c·∫ßn th√™m th√¥ng tin"
        elif is_fake and confidence > 0.8:
            message = "C√≥ d·∫•u hi·ªáu m·∫°nh c·ªßa tin gi·∫£"
        elif is_fake:
            message = "C√≥ m·ªôt s·ªë d·∫•u hi·ªáu ƒë√°ng ng·ªù"
        elif confidence > 0.8:
            message = "C√≥ v·∫ª l√† tin ƒë√°ng tin c·∫≠y"
        else:
            message = "Ph√¢n t√≠ch ho√†n t·∫•t"

        return {
            'is_fake': is_fake,
            'confidence': round(confidence, 3),
            'message': message,
            'processed_text': processed_text,
            'analysis_details': analysis_details,
            # Backward compatibility
            'suspicious_words_found': suspicious_found,
            'reliable_indicators_found': reliable_found,
            # Th√™m th√¥ng tin debug (c√≥ th·ªÉ b·ªè trong production)
            'debug_info': {
                'text_length': len(text),
                'processed_length': len(processed_text),
                'decision_threshold': 0.55,
                'algorithm_version': '2.1_improved'
            }
        }

    except Exception as e:
        return {
            'is_fake': False,
            'confidence': 0.5,
            'message': f'L·ªói khi ph√¢n t√≠ch: {str(e)}',
            'processed_text': '',
            'analysis_details': {'error': str(e)}
        }


def summarize_text(text):
    """
    T√≥m t·∫Øt vƒÉn b·∫£n t·ªëi ∆∞u - g·ªçn g√†ng v√† hi·ªáu qu·∫£
    """
    try:
        if not text or len(text.strip()) < 80:
            return {
                'summary': text.strip(),
                'compression_ratio': 1.0,
                'message': 'VƒÉn b·∫£n qu√° ng·∫Øn'
            }

        # T√°ch c√¢u nhanh
        sentences = [s.strip() for s in re.split(r'[.!?]+', text.strip()) if s.strip()]

        if len(sentences) <= 2:
            return {
                'summary': text.strip(),
                'compression_ratio': 1.0,
                'message': 'ƒê√£ g·ªçn'
            }

        # T·ª´ kh√≥a quan tr·ªçng t·ªëi ∆∞u
        key_words = ['quan tr·ªçng', 'ch√≠nh', 'k·∫øt qu·∫£', 'quy·∫øt ƒë·ªãnh', 'th√¥ng b√°o', 'cho bi·∫øt']

        # T√≠nh ƒëi·ªÉm nhanh cho t·ª´ng c√¢u
        scored_sentences = []
        for i, sentence in enumerate(sentences):
            words = sentence.lower().split()
            score = 0

            # ƒêi·ªÉm v·ªã tr√≠ (c√¢u ƒë·∫ßu v√† cu·ªëi quan tr·ªçng)
            if i == 0:
                score += 2
            elif i == len(sentences) - 1:
                score += 1
            elif i < len(sentences) * 0.3:
                score += 0.5

            # ƒêi·ªÉm ƒë·ªô d√†i (c√¢u 8-20 t·ª´ t·ªëi ∆∞u)
            if 8 <= len(words) <= 20:
                score += 1
            elif len(words) < 4:
                score -= 1

            # ƒêi·ªÉm t·ª´ kh√≥a
            score += sum(0.3 for word in key_words if word in sentence.lower())

            scored_sentences.append((sentence, score))

        # Ch·ªçn top 30-50% c√¢u t·ªët nh·∫•t
        scored_sentences.sort(key=lambda x: x[1], reverse=True)
        target_count = max(1, min(3, len(sentences) // 3))

        selected = scored_sentences[:target_count]
        selected.sort(key=lambda x: sentences.index(x[0]))  # Gi·ªØ th·ª© t·ª± g·ªëc

        # T·∫°o t√≥m t·∫Øt
        summary = '. '.join([s[0] for s in selected]) + '.'
        compression_ratio = len(summary) / len(text)

        return {
            'summary': summary,
            'compression_ratio': round(compression_ratio, 3),
            'message': f'R√∫t g·ªçn {len(sentences)}‚Üí{len(selected)} c√¢u'
        }

    except Exception as e:
        # Fallback ƒë∆°n gi·∫£n
        words = text.split()
        if len(words) > 50:
            summary = ' '.join(words[:30]) + '...'
            return {
                'summary': summary,
                'compression_ratio': 0.6,
                'message': 'T√≥m t·∫Øt c∆° b·∫£n'
            }
        return {
            'summary': text,
            'compression_ratio': 1.0,
            'message': 'L·ªói nh·ªè, gi·ªØ nguy√™n'
        }


def analyze_topic(text):
    """
    Ph√¢n t√≠ch ch·ªß ƒë·ªÅ c·ªßa vƒÉn b·∫£n s·ª≠ d·ª•ng LDA model
    """
    try:
        import joblib
        import numpy as np
        import os
        import json

        # ƒê∆∞·ªùng d·∫´n ƒë·∫øn model
        model_dir = os.path.join('ml_models', 'topic_model')
        lda_model_path = os.path.join(model_dir, 'lda_model.joblib')
        vectorizer_path = os.path.join(model_dir, 'vectorizer_bow.joblib')
        topics_path = os.path.join(model_dir, 'topics.json')

        # Ki·ªÉm tra file t·ªìn t·∫°i
        if not all(os.path.exists(path) for path in [lda_model_path, vectorizer_path, topics_path]):
            return fallback_topic_analysis(text)

        # Load model v√† vectorizer
        lda_model = joblib.load(lda_model_path)
        vectorizer = joblib.load(vectorizer_path)

        # Load topic mapping
        with open(topics_path, 'r', encoding='utf-8') as f:
            topic_keywords = json.load(f)

        # Preprocess text
        processed_text = preprocess_text(text)

        # Transform text to vector
        text_vector = vectorizer.transform([processed_text])

        # Predict topic probabilities
        topic_probs = lda_model.transform(text_vector)[0]

        # L·∫•y topic c√≥ x√°c su·∫•t cao nh·∫•t
        dominant_topic = np.argmax(topic_probs)
        confidence = topic_probs[dominant_topic]

        # Map topic s·ªë th√†nh t√™n ch·ªß ƒë·ªÅ d·ª±a tr√™n keywords
        topic_names = {
            '0': 'S·ª©c kh·ªèe',      # b·ªánh, th·ªÉ, c∆°, b√°c sƒ©
            '1': 'Ch√≠nh tr·ªã',     # m·ªπ, √¥ng, trump, th·ªëng
            '2': 'Gi√°o d·ª•c',      # √°n, ƒë·ªÅ, h·ªçc
            '3': 'C√¥ng ngh·ªá',     # c√¥ng, ai, d·ª•ng, nƒÉng
            '4': 'Th·ªÉ thao',      # tr·∫≠n, ƒë·ªôi, b√≥ng, th·ªß
            '5': 'ƒê·ªùi s·ªëng',      # t√¥i, ng∆∞·ªùi, con, nh√†
            '6': 'Kinh t·∫ø',       # gi√°, n∆∞·ªõc, ƒë·ªìng, b·∫£n
            '7': 'Gi√°o d·ª•c',      # h·ªçc, sinh, thi, tr∆∞·ªùng
            '8': 'Giao th√¥ng',    # xe, ng∆∞·ªùi, ƒë∆∞·ªùng, an
            '9': 'Kinh t·∫ø',       # c√¥ng, doanh, ƒë·∫ßu, kinh
            '10': 'Du l·ªãch',      # kh√°ch, du, ·∫£nh, di·ªÖn
            '11': 'Th·ªùi s·ª±'       # t·ªânh, th√†nh, c√¥ng, bay
        }

        topic_name = topic_names.get(str(dominant_topic), 'Kh√¥ng x√°c ƒë·ªãnh')

        return {
            'topic': topic_name,
            'confidence': float(confidence),
            'topic_id': dominant_topic,
            'message': f'Ph√¢n lo·∫°i th√†nh c√¥ng v·ªõi ƒë·ªô tin c·∫≠y {confidence*100:.1f}%'
        }

    except Exception as e:
        print(f"Error in LDA topic analysis: {e}")
        return fallback_topic_analysis(text)


def fallback_topic_analysis(text):
    """
    Ph√¢n t√≠ch ch·ªß ƒë·ªÅ d·ª± ph√≤ng b·∫±ng keyword matching
    """
    try:
        processed_text = preprocess_text(text)

        # T·ª´ kh√≥a cho c√°c ch·ªß ƒë·ªÅ
        topic_keywords = {
            'Ch√≠nh tr·ªã': ['ch√≠nh ph·ªß', 'b·ªô tr∆∞·ªüng', 'qu·ªëc h·ªôi', 'th·ªß t∆∞·ªõng', 'ch·ªß t·ªãch', 'ƒë·∫£ng', 'ch√≠nh tr·ªã', 'm·ªπ', 'trump'],
            'Kinh t·∫ø': ['kinh t·∫ø', 'th·ªã tr∆∞·ªùng', 'ƒë·∫ßu t∆∞', 'ch·ª©ng kho√°n', 'ng√¢n h√†ng', 't√†i ch√≠nh', 'doanh nghi·ªáp', 'gi√°', 'ƒë·ªìng'],
            'Th·ªÉ thao': ['b√≥ng ƒë√°', 'th·ªÉ thao', 'v·∫≠n ƒë·ªông vi√™n', 'world cup', 'sea games', 'olympic', 'tr·∫≠n', 'ƒë·ªôi', 'th·ªß'],
            'Gi·∫£i tr√≠': ['ngh·ªá sƒ©', 'ca sƒ©', 'di·ªÖn vi√™n', 'phim', '√¢m nh·∫°c', 'showbiz'],
            'C√¥ng ngh·ªá': ['c√¥ng ngh·ªá', 'smartphone', 'internet', 'ai', 'robot', '·ª©ng d·ª•ng'],
            'S·ª©c kh·ªèe': ['s·ª©c kh·ªèe', 'b·ªánh vi·ªán', 'b√°c sƒ©', 'thu·ªëc', 'y t·∫ø', 'covid', 'b·ªánh'],
            'Gi√°o d·ª•c': ['h·ªçc', 'sinh', 'thi', 'tr∆∞·ªùng', 'ƒëi·ªÉm', 'ƒë·∫°i h·ªçc', 'gi√°o d·ª•c'],
            'Giao th√¥ng': ['xe', 'ƒë∆∞·ªùng', 'tai n·∫°n', 'giao th√¥ng', 'm√°y'],
            'Du l·ªãch': ['du l·ªãch', 'kh√°ch', 'ƒëi·ªÉm ƒë·∫øn', 'tour'],
            'ƒê·ªùi s·ªëng': ['gia ƒë√¨nh', 'con', 'nh√†', 'cu·ªôc s·ªëng']
        }

        topic_scores = {}

        for topic, keywords in topic_keywords.items():
            score = sum(1 for keyword in keywords if keyword in processed_text)
            if score > 0:
                topic_scores[topic] = score

        if topic_scores:
            best_topic = max(topic_scores, key=topic_scores.get)
            max_score = topic_scores[best_topic]
            confidence = min(max_score / 10.0, 1.0)  # Normalize confidence

            return {
                'topic': best_topic,
                'confidence': confidence,
                'topic_id': -1,
                'message': f'Ph√¢n lo·∫°i b·∫±ng keywords v·ªõi {max_score} t·ª´ kh√≥a kh·ªõp'
            }
        else:
            return {
                'topic': 'Kh√¥ng x√°c ƒë·ªãnh',
                'confidence': 0.0,
                'topic_id': -1,
                'message': 'Kh√¥ng t√¨m th·∫•y t·ª´ kh√≥a ph√π h·ª£p'
            }

    except Exception as e:
        return {
            'topic': 'Kh√¥ng x√°c ƒë·ªãnh',
            'confidence': 0.0,
            'topic_id': -1,
            'message': f'L·ªói ph√¢n t√≠ch: {str(e)}'
        }


def analyze_sentiment(text):
    """
    Ph√¢n t√≠ch c·∫£m x√∫c c·ªßa vƒÉn b·∫£n s·ª≠ d·ª•ng RoBERTa model
    """
    try:
        # ƒê∆∞·ªùng d·∫´n ƒë·∫øn model
        model_dir = os.path.join('ml_models', 'news_sentiment_pol3')

        # Ki·ªÉm tra model t·ªìn t·∫°i
        if not os.path.exists(model_dir):
            return fallback_sentiment_analysis(text)

        # Load tokenizer v√† model
        tokenizer = AutoTokenizer.from_pretrained(model_dir)
        model = AutoModelForSequenceClassification.from_pretrained(model_dir)

        # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
        processed_text = text.strip()
        if len(processed_text) > 512:
            # C·∫Øt vƒÉn b·∫£n n·∫øu qu√° d√†i (RoBERTa c√≥ gi·ªõi h·∫°n 512 tokens)
            processed_text = processed_text[:512]

        # Tokenize
        inputs = tokenizer(
            processed_text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=256
        )

        # Predict
        with torch.no_grad():
            outputs = model(**inputs)
            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
            predicted_class = torch.argmax(predictions, dim=-1).item()
            confidence = predictions[0][predicted_class].item()

        # Mapping labels
        label_mapping = {
            0: 'ti√™u c·ª±c',    # neg
            1: 'trung t√≠nh',   # neu
            2: 't√≠ch c·ª±c'      # pos
        }

        sentiment_label = label_mapping.get(predicted_class, 'kh√¥ng x√°c ƒë·ªãnh')

        # Emoji mapping
        emoji_mapping = {
            'ti√™u c·ª±c': 'üò¢',
            'trung t√≠nh': 'üòê',
            't√≠ch c·ª±c': 'üòä'
        }

        return {
            'sentiment': sentiment_label,
            'confidence': float(confidence),
            'sentiment_id': predicted_class,
            'emoji': emoji_mapping.get(sentiment_label, '‚ùì'),
            'message': f'Ph√¢n t√≠ch c·∫£m x√∫c ho√†n t·∫•t v·ªõi ƒë·ªô tin c·∫≠y {confidence*100:.1f}%'
        }

    except Exception as e:
        print(f"Error in sentiment analysis: {e}")
        return fallback_sentiment_analysis(text)


def fallback_sentiment_analysis(text):
    """
    Ph√¢n t√≠ch c·∫£m x√∫c d·ª± ph√≤ng b·∫±ng keyword matching
    """
    try:
        processed_text = text.lower()

        # T·ª´ kh√≥a c·∫£m x√∫c
        positive_words = [
            't·ªët', 'tuy·ªát v·ªùi', 'xu·∫•t s·∫Øc', 'h·∫°nh ph√∫c', 'vui', 'th√†nh c√¥ng',
            't√≠ch c·ª±c', 'ho√†n h·∫£o', '·∫•n t∆∞·ª£ng', 'h√†i l√≤ng', 'th·∫Øng l·ª£i',
            'khuy·∫øn kh√≠ch', 'hy v·ªçng', 'l·∫°c quan', 'ph√°t tri·ªÉn', 'ti·∫øn b·ªô'
        ]

        negative_words = [
            'x·∫•u', 't·ªá', 'kh·ªßng khi·∫øp', 'bu·ªìn', 'th·∫•t b·∫°i', 'ti√™u c·ª±c',
            'th·∫•t v·ªçng', 'lo l·∫Øng', 'kh√≥ khƒÉn', 'v·∫•n ƒë·ªÅ', 'tai n·∫°n',
            'b·ªánh', 'ch·∫øt', 'm·∫•t', 'thi·ªát h·∫°i', 'nguy hi·ªÉm', 'kh·ªßng ho·∫£ng'
        ]

        positive_score = sum(1 for word in positive_words if word in processed_text)
        negative_score = sum(1 for word in negative_words if word in processed_text)

        if positive_score > negative_score:
            sentiment = 't√≠ch c·ª±c'
            confidence = min(0.6 + (positive_score - negative_score) * 0.1, 0.85)
            sentiment_id = 2
            emoji = 'üòä'
        elif negative_score > positive_score:
            sentiment = 'ti√™u c·ª±c'
            confidence = min(0.6 + (negative_score - positive_score) * 0.1, 0.85)
            sentiment_id = 0
            emoji = 'üò¢'
        else:
            sentiment = 'trung t√≠nh'
            confidence = 0.5
            sentiment_id = 1
            emoji = 'üòê'

        return {
            'sentiment': sentiment,
            'confidence': confidence,
            'sentiment_id': sentiment_id,
            'emoji': emoji,
            'message': f'Ph√¢n t√≠ch b·∫±ng keywords v·ªõi {positive_score + negative_score} t·ª´ kh√≥a kh·ªõp'
        }

    except Exception as e:
        return {
            'sentiment': 'kh√¥ng x√°c ƒë·ªãnh',
            'confidence': 0.0,
            'sentiment_id': -1,
            'emoji': '‚ùì',
            'message': f'L·ªói ph√¢n t√≠ch c·∫£m x√∫c: {str(e)}'
        }

